{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\denni\\Documents\\Thesis_2024\\thesis_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BloomForCausalLM, BloomTokenizerFast\n",
    "import torch\n",
    "from methods import *\n",
    "torch.cuda.empty_cache()\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/SEAT_var1.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "t1_1 = data['list1']\n",
    "t2_1 = data['list2']\n",
    "a1_1 = data['list3']\n",
    "a2_1 = data['list4']\n",
    "with open('./Data/SEAT_var2.json', 'r') as file:\n",
    "    data2 = json.load(file)\n",
    "t1_2 = data2['list1']\n",
    "t2_2 = data2['list2']\n",
    "a1_2 = data2['list3']\n",
    "a2_2 = data2['list4']\n",
    "with open('./Data/SEAT_var3.json', 'r') as file:\n",
    "    data3 = json.load(file)\n",
    "t1_3 = data3['list1']\n",
    "t2_3 = data3['list2']\n",
    "a1_3 = data3['list3']\n",
    "a2_3 = data3['list4']\n",
    "with open('./Data/SEAT_var4.json', 'r') as file:\n",
    "    data4 = json.load(file)\n",
    "t1_4 = data4['list1']\n",
    "t2_4 = data4['list2']\n",
    "a1_4 = data4['list3']\n",
    "a2_4 = data4['list4']\n",
    "with open('./Data/SEAT_var5.json', 'r') as file:\n",
    "    data5 = json.load(file)\n",
    "t1_5 = data5['list1']\n",
    "t2_5 = data5['list2']\n",
    "a1_5 = data5['list3']\n",
    "a2_5 = data5['list4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### larger value (both pos and neg) --> larger bias\n",
    "### positive SEAT score: t1 has strong association with a1, and/or t2 has strong association with a2\n",
    "### negative SEAT score: t1 has strong association with a2, and/or t2 has strong association with a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOOM-560M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bigscience/bloom-560m\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "model = BloomForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9189126\n",
      "0.87122136\n",
      "0.9339675\n",
      "0.25025833\n",
      "1.922369\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0561302\n",
      "0.92890024\n",
      "1.036777\n",
      "1.1782961\n",
      "1.6567035\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOOM-1.1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bigscience/bloom-1b1\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "model = BloomForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6151807\n",
      "1.680844\n",
      "1.6705861\n",
      "0.005520666\n",
      "1.9283046\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7909661\n",
      "0.90050036\n",
      "0.7632419\n",
      "1.235059\n",
      "1.5492069\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOOM-1.7B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bigscience/bloom-1b7\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "model = BloomForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0423645\n",
      "1.0646405\n",
      "1.1260799\n",
      "-0.1773039\n",
      "1.8768251\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80332667\n",
      "0.9692576\n",
      "0.630306\n",
      "0.63989604\n",
      "1.1294574\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLOOM-3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bigscience/bloom-3b\"\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "model = BloomForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2450368\n",
      "1.1743349\n",
      "1.3084453\n",
      "-0.034374774\n",
      "1.9382606\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38151076\n",
      "0.44371405\n",
      "0.4429682\n",
      "0.582968\n",
      "1.6039947\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'last'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBIASED BLOOM-560M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = '../Models/DB_BLOOM'\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom-560m\")\n",
    "model = BloomForCausalLM.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968931\n",
      "1.0074455\n",
      "1.0625732\n",
      "-0.12444891\n",
      "1.8875014\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'avg'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'avg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63106644\n",
      "0.59325033\n",
      "0.6191349\n",
      "0.14421697\n",
      "1.3300842\n"
     ]
    }
   ],
   "source": [
    "print(seat_score(t1_1, t2_1, a1_1, a2_1, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_2, t2_2, a1_2, a2_2, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_3, t2_3, a1_3, a2_3, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_4, t2_4, a1_4, a2_4, tokenizer, model, 'last'))\n",
    "print(seat_score(t1_5, t2_5, a1_5, a2_5, tokenizer, model, 'last'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
